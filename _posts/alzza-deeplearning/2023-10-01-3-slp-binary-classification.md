---
title: "단층 퍼셉트론(SLP) - 이진 판단"
last_modified_at: 2023-10-01T12:53:12+09:00
categories:
    - alzza-deeplearning
tags:
    - A.I

toc: true
toc_label: "My Table of Contents"
author_profile: true

---

# 이진 판단 문제의 신경망 처리
이진 판단 문제는 예/아니오 혹은 0/1 같은 두 가지 값 중 하나로 답하는 문제다. 가중치와 편향을 이용하는 퍼셉트론의 연산은 두 가지 값으로 결과를 제한하기 힘들다.

이 때문에 선형 연산에서 범위에 제한이 없는 실숫값을 생산하고, 이를 확률값의 성질에 맞게 변환해주는 비선형함수인 시그모이드 함수를 사용한다.

이제 시그모이드 함수에 맞는 손실함수를 정의하여야한다. 즉 값이 0 이상이면서 추정이 정확해질수록 작아지는 성질이 있는 손실 함수를 정의해야한다.

시그모이드 함수에서는 손실함수를 교차 엔트로피로 사용한다. 교차 엔트로피란 두 가지 확률 분포가 얼마나 다른지를 숫자 하나로 표현해주는 것으로, 이진 판단 문제를 다룰 수 있게 되었다.

왜 시그모이드 함수에 MSE를 사용하면 안되는지는 시그모이드 함수를 살펴보고 정리하자.

# 시그모이드 함수
시그모이드 함수는 범위에 제한이 없는 임의의 실숫값을 입력으로 받아 확률값의 범위에 해당하는 0과 1 사이의 값을 출력하는 함수이다. $\sigma (x)$ 로 표현한다. 여기서 입력x를 확률값의 logit 표현이라고 한다. 

로짓값은 상대적이다. A 확률의 로짓값이 5, B확률의 로짓값이 2라면 A확률은 B확률보다 $e^{5-2} = e^3$ 배 정도 크다.

시그모이드 함수는 입력값을 답이 참일 가능성을 로짓으로 표시한 값으로 간주한다. 이때 답이 거짓일 경우의 로짓값을 0으로 간주한다.

예를 들어 A일 가능성의 로짓값이 0.5일 경우 A가 아닐 가능성의 로짓값은 0이고 두 확률의 합은 1이어야되므로, $e^0.5$ 와 $e^0$ 의 합 대비 $e^0.5$ 와 $e^0$ 의 비율을 보면된다. 따라서 A일 확률은 $\frac{e^0.5}{e^0.5 + 1}$ 이고, A가 아닐 확률은 $\frac{1}{e^0.5 + 1}$ 이다.

이를 일반화하면 답이 참일 가능성의 로짓값 x, 답이 거짓일 가능성의 로짓값을 0이라 할때 답이 참일 확률은 $\frac{e^x}{e^x + 1}$ 이고 분모와 분자를 $e^x$ 로 나누면 $\frac{1}{1+e^{-x}}$ 이다. 따라서 시그모이드 함수는 다음과 같이 정의된다.

$$ \sigma (x) = \frac{1}{1+e^{-x}}$$

또한 시그모이드 함수의 그래프는 아래와 같다.
![graph of sigmoid function](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/b004a023-c67d-48a1-8486-f11186eea1af)

(사진1 : 시그모이드 함수의 그래프: Powered by desmos)

또한 0.51의 확률로 참을 선택하는 것과 0.99의 확률로 참을 선택하는 것은 의미가 다르다. 0.51의 확률로 참을 선택했을 때보다, 0.99의 확률로 참을 선택했는데 거짓일 경우 더 많은 파라미터 수정이 이루어져야한다. 그러나 시그모이드 함수에 MSE를 적용하면 그것이 불가능하다.

![시그모이드 함수의 MSE적용한 그래프](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/09600ce2-9830-4ee5-afe9-24e57932bcfa)

(사진2: 시그모이드 함수에 MSE를 적용한 그래프, 실제 확률이 1이라고 가정, 입력 데이터의 로짓값이 3이라고 하였을 때 w에 따른 손실함수)

![시그모이드 함수의 MSE적용한 그래프](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/5410590e-e0fe-4c9d-aba4-d09b584a46e4)

(사진3: 시그모이드 함수에 MSE를 적용한 그래프, 실제 확률이 0.5이라고 가정, 입력 데이터의 로짓값이 3이라고 하였을 때 w에 따른 손실함수)

위 두 그래프는 시그모이드 함수에 MSE를 적용한 그래프( $ y=(\frac{1}{1+e^{-wx_i}}-y_i)^2 $ )로, w에 따른 손실함수를 나타내고있다. 위 두 그래프에서 알 수 있듯, 손실함수가 클수록 파라미터가 대폭 수정될려면 손실함수가 클때 기울기가 커야하지만, 기울기가 작다. 따라서 손실함수가 클때, 학습속도가 대단히 느려지거나 기울기를 0으로 인식하여 학습을 멈출 수도 있다. 따라서 시그모이드 함수에 MSE를 적용하는 것은 하지 않는 것이 좋다.

## 시그모이드 함수의 미분
시그모이드 함수의 미분은 다음과 같이 구할 수 있다. $y=\frac{1}{g(x)}$ 일때

$$ y'=\frac{-g'(x)}{g(x)^2}$$

이므로

$$ \sigma ' (x) = \frac{-(1+e^{-x})'}{(1+e^{-x})^2} = \frac{e^{-x}}{(1+e^{-x})^2} = \frac{(1+e^{-x})-1}{(1+e^{-x})^2} = \frac{1}{1+e^{-x}} (1- \frac{1}{1+e^{-x}}) = \sigma (x) (1-\sigma (x))$$

따라서 시그모이드 함수의 미분은

$$\sigma ' (x) =  \sigma (x) (1-\sigma (x))$$

이다.

# 확률 분포와 정보 엔트로피
정보 엔트로피란 확률 분포의 무질서도나 불확실성 또는 정보 표현의 부담정도를 나타내는 것이다.

