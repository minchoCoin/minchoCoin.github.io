---
title: "복합 출력의 처리 방법 - 오피스31 다차원 분류 신경망"
last_modified_at: 2023-11-20T19:18:12+09:00
categories:
    - alzza-deeplearning
tags:
    - A.I

toc: true
toc_label: "My Table of Contents"
author_profile: true

---
# 목적
꽃 이미지 분류 신경망과 오피스 31 다차원 분류 신경망을 CNN을 적용하여 실행하여 보고 그 결과를 확인하고 분석해본다.

# 실험 원리

## 다층 퍼셉트론의 문제점
다층 퍼셉트론에서 한 퍼셉트론은 인접한 양쪽 계층의 모든 퍼셉트론과 연결되어있다. 즉 다층 퍼셉트론 신경망의 은닉 계층을 완전 연결 계층이라 부른다.

가중치 행렬 형태는 입력 벡터 크기와 출력 벡터 크기에 따라 결정되고, 특히 이미지 데이터의 경우 입력 벡터 크기가 커서 매우 큰 가중치 파라미터를 갖게 된다. 이럴 경우 메모리 부담과 학습 느려짐, 그리고 지나치게 많은 데이터 필요 등의 문제가 발생할 수 있다.

## 합성곱 계층
합성곱 게층은 작은 사각 모양의 가중치 파라미터(합성곱 커널 가중치)를 이용하여 입력 픽셀값들로부터 출력 픽셀값을 계산한다. 출력 픽셀은 합성곱 커널 가중치의 영역에 들어가는 입력 픽셀값과 커널 가중치들을 짝지어 곱한 후 커널의 편향값과 합산해 구한다. 이때 입력 픽셀 행렬에 커널이 이동하며 반복 적용되면서 출력 픽셀을 계산한다. 6x6형태의 입력 픽셀값 36개로부터 같은 크기의 출력 픽셀을 생성할 때 완전 연결 계층을 사용하면 36x36+36=1332의 파라미터수가 필요하다. 그러나 3x3크기의 합성곱 커널과 1개의 커널 편향을 사용하여 합성곱 연산을 하면 3x3+1=10개의 파라미터만 필요하다.

커널을 사용하면 위와같이 파라미터 수를 줄여주고, 또한 커널의 반복 이용으로 커널에 대한 학습 횟수가 늘어나는 효과가 생겨 학습이 빠르게 이루어지고, 같은 커널이 모든 위치에 적용되어 한 곳에서 포착된 패턴이 다른 곳에 이용될 수도 있다.

## 합성곱 연산의 패딩과 건너뛰기
합성곱 계층에서 출력 픽셀값을 계산하려고 할 때, 출력 픽셀값의 경계 부분을 계산하려고 하면 입력 픽셀값의 범위를 넘어설 수 있다. 예를 들어 6x6의 입력 픽셀과 출력 픽셀이 있고, 3x3의 합성곱 커널이 있으면, 맨 왼쪽 상단의 출력 픽셀을 계산하기 위해서는 입력 픽셀 맨 왼쪽 상단의 값을 기준으로 상하좌우 및 대각선의 값이 필요하지만 없는 값들이 있다. 이런 문제를 해결하는 방법을 패딩이라고 한다. SAME과 VALID 방식이 있다.

SAME 패딩 방식은 전체 입력 행렬 주위를 0으로 둘러싸 확장한다. 위의 3x3 합성곱 커널을 이용할 경우 출력 픽셀 가장자리 값을 계산할 때 입력 행렬 주위를 0으로 1칸 둘러싸면 계산할 수 있다. SAME 패딩 방식에서는 입력과 같은 크기의 출력이 만들어진다.

VALID 패딩 방식은 입력 범위를 벗어나지 않을 때만 출력 픽셀을 생성한다. 예를들어 3x3 커널의 경우 입력 픽셀의 가장자리로부터 한 칸 이상 안쪽에 있는 위치에서만 출력 픽셀을 생성할 수 있다. 따라서 6x6 입력 픽셀에서 4x4의 출력 픽셀이 나오게 된다. 즉 VALID 방식에서는 출력 이미지의 크기가 입력 이미지 크기보다 줄어들게 된다.

또한 합성곱 계층으로 출력을 생성할 때 일정한 간격으로 건너뛰면서 픽셀을 만들 수도 있다. 이때 건너뛰는 정도를 지정하는 값을 건너뛰기 보폭 또는 보폭(stride)라고 한다. 6x6 입력 행렬을 3x3 합성곱 커널을 이용하여 (2,3)의 건너뛰기 보폭을 이용하여 연산하면 출력 행렬은 3x2의 크기가 된다.

## 폴링 계층
폴링은 일정 영역의 입력 픽셀값들로부터 그 최대치나 평균치 같은 대푯값을 구해 출력 픽셀로 생성하는 처리이다. 예를 들어 6x6 픽셀을 2x2 픽셀 9개로 나누어 각 2x2 픽셀에서 최댓값을 출력 픽셀로 하면 최대치 풀링 처리이고, 평균값을 출력 픽셀로 하면 평균치 폴링 처리이다.

이미지 크기와 커널 크기, 그리고 보폭의 관계는 다음과 같다. 먼저 커널 크기와 보폭이 서로 다른 경우, 출력 픽셀 생성을 위해 확인해야할 입력 영역들이 서로 겹치거나 비는 영역이 생기면서 처리가 불편해진다. 이를 해결하기 위한 가장 쉬운 방법은 모든 입력 픽셀 위치에 대응하는 출력 픽셀을 구한 후 건너뛰기로 걸러내 최종 결과를 생성하는 것이다. 

커널 크기와 보폭이 동일하고, 이미지 크기가 커널 크기의 배수가 아닌 경우, 입력 픽셀을 커널 크기로 분할하여 각 분할된 커널의 대표값을 뽑아 곧바로 출력 픽셀을 구할 수 있으나, 가장자리에서 입력 범위를 벗어나는 경우가 있기 때문에 추가 처리가 필요해진다.

커널 크기와 보폭이 동일하고, 이미지 크기가 커널 크기의 배수인 경우, 입력 픽셀을 커널 크기로, 입력 범위를 벗어나는 경우없이 분할할 수 있어 효율적인 처리가 가능해진다.

폴링 계층을 이용하면, 특히 합성곱 계층 사이에 배치되면 작은 해상도에 정보가 집약되게 만들게할 수 있다. 즉, 합성곱 계층이 미세한 변화에 휘둘리지 않고 필요한 패턴을 쉽게 포착할 수 있게 해준다.

## 채널의 도입과 커널의 확장
이미지에는 다양한 패턴과 특징이 있을 수 있으므로, 한 가지 특징맵(합성곱 계층에서 출력되는 픽셀 이미지)으로 충분하지 않다. 따라서 합성곱 신경망이 다루는 이미지 데이터에는 가로 및 세로 해상도 외에도 채널이라는 차원이 추가된다. 보통 흑백 이미지에는 채널 하나, 컬러 이미지에는 채널 세 개를 할당한다.
그리고 보통, 이미지 처리에서 커널은 4차원 구조인데, 사각 영역 입력의 모든 채널을 이용하여 특징맵을 만들어내고(3차원), 출력 채널 수만큼 특징맵을 만들어내기 위해 커널이 채널 수만큼 있어야하기 때문이다.
또한 합성곱 계층의 입출력 데이터 역시 4차원 구조인데, [미니배치 크기, 입력 이미지 행 수, 입력 이미지 열 수, 입력 채널 수]로 구성되어있다.
입력 데이터의 형태를 $ [mb,xh,xw,xchn] $, 커널의 형태를 $[kh,kw,xchn,ychn]$, 출력 데이터의 형태를 $[mb,yh,yw,ychn]$이라 하고, SAME 패딩 방식과 건너뛰기 처리가 없다고 가정하면 $yh=xh,yw=xw$ 가 되면서 출력이 $[mb,xh,xw,ychn]$ 의 형태가 되어 출력 원소는 다음과 같이 계산된다.

$$y_{n,r,c,m} = \sum _ {i=1} ^ {kh} \sum _ {j=1} ^ {kw} \sum _ {k=1} ^ {xchn} k_{i,j,k,m} x_{n,r+i-bh,c+j-bw,k} $$

여기서 mb는 미니배치 크기, xh는 입력 데이터의 세로크기, xw는 입력 데이터의 가로크기, xchn은 입력 크기의 채널 개수, kh는 커널의 세로크기, kw는 커널의 세로 크기, yh는 출력 데이터의 세로크기, yw는 출력 데이터의 가로크기, ychn은 출력 데이터의 채널 개수이다. 위의 식에서 커널 행렬 중 좌표 (i,j,k,m)에 있는 값은 입력 행렬 중 좌표 (n,r+i-bh,c+j-bw,k)에 있는 값과 곱하여 출력 좌표 (n,r,c,k)에 해당하는 값을 계산한다. (bh,bw) 는 ((kh-1)//2, (kw-1)//2) 이다.

## 합성곱의 역전파 처리
합성곱 계층의 역전파 처리는 완전 연결 계층의 역전파 처리와 비슷하다. 입력 픽셀과 커널 가중치를 짝지어 곱하기 때문에 커널 가중치와 입력 픽셀은 서로가 서로의 계수로서 편미분 값이 된다. 이 편미분값에 출력 성분의 손실 기울기를 곱하면 입력 픽셀과 커널 가중치의 해당 출력 성분에 대한 손실 기울기값을 구할 수 있다.

## 폴링 계층의 역전파 처리
최대치 풀링에서, 출력에 반영되는 것은 커널 영역의 최댓값이므로, 최대치로 선정된 입력만 손실 기울기를 전달하고, 나머지의 손실 기울기는 0으로 설정하면 된다(만약 커널 영역에서 최대값이 여러개 있는 경우, 그중 하나를 임의로 정해 손실 기울기를 몰아주거나, 동점인 모든 원소에 손실 기울기를 중복 전달하거나 균등하게 전달하는 방법이 있다).

평균치 폴링의 경우 입력 원소가 출력에 균등하게 반영되므로, 출력의 손실 기울기를 입력 원소들에 균등하게 나누어주면 된다.

## 합성곱 신경망의 일반적인 구성
합성곱 계층이나 폴링 계층 앞에 완전 연결 계층을 두는 것은 바람직하지 않다. 완전 연결 때문에 이미지의 지역적 특성이 없어지기 때문이다. 그러나 신경망 마지막의 완전 연결 계층은 필요하다. 여러 채널에 흩어져있는 정보를 종합하여 문제 해결에 필요한 형태의 출력을 생성해야하기 때문이다.

일반적으로 합성곱 계층 – 폴링 계층 – 합성곱 계층 – 폴링 계층 – 완전 연결 계층으로 배치하게 된다.

# 실험 방법
1. 이미지를 96x96 크기로 만든다.
2. 꽃 이미지 분류 신경망
    1. (30,10)의 은닉계층을 가지는(완전 연결 계층) 모델을 아담 알고리즘을 적용하여 학습하고 결과를 확인한다.
    2. 1의 모델을 아담 알고리즘을 적용하지 않고 학습하고 결과를 확인한다.
    3. 5x5 크기의 커널로 12채널을 만들어내는 합성곱 계층과, 4x4 크기의 최대치 풀링 계층, 3x3 크기의 커널로 12채널을 만들어내는 합성곱 계층과 2x2 크기의 평균치 풀링 계층으로 학습하고 결과를 확인한다.
    4. 3x3 크기의 커널로 6채널을 만들어내는 합성곱 계층과, 2x2 크기의 최대치 풀링 계층, 3x3 크기의 커널로 12채널을 만들어내는 합성곱 계층과 2x2 크기의 최대치 풀링 계층, 3x3 크기의 커널로 24채널을 만들어내는 합성곱 계층과 3x3 크기의 평균치 풀링 계층으로 학습하고 결과를 확인한다.

3. 오피스31 다차원 분류 신경망
    1. 3x3 크기의 커널로 6채널을 만들어내는 합성곱 계층과, 2x2 크기의 최대치 풀링 계층, 3x3 크기의 커널로 12채널을 만들어내는 합성곱 계층과 2x2 크기의 최대치 풀링 계층, 3x3 크기의 커널로 24채널을 만들어내는 합성곱 계층과 3x3 크기의 평균치 풀링 계층으로 학습하고 결과를 확인한다.
    2. 1의 모델에서 비선형 활성화 함수를 시그모이드 함수로 하여 학습하고 결과를 확인한다.
    3. 1의 모델에서 비선형 활성화 함수를 쌍곡 탄젠트 함수로 하여 학습하고 결과를 확인한다.

# 실험 결과

## 꽃 이미지 분류 신경망

### (30,10)의 은닉계층을 가지는(완전 연결 계층) 모델(아담 알고리즘 적용)

![그림 1 꽃 이미지 분류 신경망에서 (30,10)의 은닉 계층을 가지는 모델(아담 알고리즘 적용) 실험 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/81b41cbc-f8b1-470a-90bd-bb4aec336a10)

(그림 1 꽃 이미지 분류 신경망에서 (30,10)의 은닉 계층을 가지는 모델(아담 알고리즘 적용) 실험 결과)

훈련 데이터의 정확도는 0.358, 검증 데이터의 정확도는 0.240이다. 테스트 데이터의 정확도는 0.311이다. 정답이 (daisy, sunflower, tulip)에 대한 데이터에 대해 (sunflower,sunflower,sunflower)로 예측하였다.

### (30,10)의 은닉계층을 가지는(완전 연결 계층) 모델(아담 알고리즘 미적용)

![그림 2 꽃 이미지 분류 신경망에서 (30,10)의 은닉 계층을 가지는 모델(아담 알고리즘 미적용) 실험 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/64d7b282-e20f-4c06-ba32-437e4a44cbfa)

(그림 2 꽃 이미지 분류 신경망에서 (30,10)의 은닉 계층을 가지는 모델(아담 알고리즘 미적용) 실험 결과)

훈련 데이터의 정확도는 0.454, 검증 데이터의 정확도는 0.350이다. 테스트 데이터의 정확도는 0.388이다. 정답이 (rose, dandelion, sunflower)에 대한 데이터에 대해 (rose, dandelion,dandelion)로 예측하였다.

### 5x5 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 4x4의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층 적용

![그림 3 꽃 이미지 분류 신경망에서 5x5 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 4x4의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층 적용하여 학습한 결과1](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/7c441d97-153c-41ad-be1b-7d0cc671c867)
![그림 3 꽃 이미지 분류 신경망에서 5x5 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 4x4의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층 적용하여 학습한 결과2](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/185046ca-7743-4f6b-8ec7-6a932b33d1b3)

(그림 3 꽃 이미지 분류 신경망에서 5x5 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 4x4의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층 적용하여 학습한 결과)

훈련 데이터의 정확도는 0.778, 검증 데이터의 정확도는 0.490이다. 테스트 데이터의 정확도는 0.548이다. 정답이 (daisy, sunflower, rose)에 대한 데이터에 대해 (dandelion, rose, rose)로 예측하였다.

### 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용

![그림 4 꽃 이미지 분류 신경망에서 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용하여 학습한 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/d08af7c8-abe9-46e0-8f62-23e83afe2f9f)

(그림 4 꽃 이미지 분류 신경망에서 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용하여 학습한 결과)

훈련 데이터의 정확도는 0.783, 검증 데이터의 정확도는 0.640이다. 테스트 데이터의 정확도는 0.613이다. 정답이 (daisy, sunflower, rose)에 대한 데이터에 대해 (dandelion, rose, rose)로 예측하였다.

## 오피스31 다차원 분류 신경망

### 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용

![그림 5 오피스31 다차원 분류 신경망에서, 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용한 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/0bbd3824-b1c0-4bec-8c6b-8cf4c1b4d8bf)

(그림 5 오피스31 다차원 분류 신경망에서, 3x3 합성곱 커널로 6채널을 만들어내는 합성곱 계층과 2x2의 최대치 폴링 계층, 3x3 합성곱 커널로 12채널을 만들어내는 합성곱 계층과 2x2의 평균치 폴링 계층, 3x3 합성곱 커널로 24채널을 만들어내는 합성곱 계층과 3x3의 평균치 폴링 계층 적용한 결과)

훈련 데이터의 정확도는 0.966+0.937, 검증 데이터의 정확도는 0.850+0.550이다. 테스트 데이터의 정확도는 0.901+0.536이다. 정답이 (amazon,amazon,amazon)에 대한 데이터에 대해 (amazon,amazon,amazon)로 예측하였고, 정답이 (punchers, tape_dispenser, trash can)인 데이터에 대해 (punchers, mouse, bookcase)로 예측하였다.
(정확도에서 x+y의 뜻은, 도메인 정확도가 x, 품목 정확도가 y라는 뜻이다)

### 위의 신경망의 비선형 활성화 함수를 시그모이드로 적용

![그림 6 위의 신경망의 비선형 활성화 함수를 시그모이드로 적용한 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/b968de58-ae8e-407e-bb51-2b4b70dcfbb0)

(그림 6 위의 신경망의 비선형 활성화 함수를 시그모이드로 적용한 결과)

훈련 데이터의 정확도는 0.686+0.039, 검증 데이터의 정확도는 0.650+0.040이다. 테스트 데이터의 정확도는 0.693+0.043이다. 정답이 (amazon,amazon,webcam)에 대한 데이터에 대해 (amazon,amazon,amazon)로 예측하였고, 정답이 (stapler,calculator,bottle)인 데이터에 대해 (monitor,monitor,monitor)로 예측하였다.
(정확도에서 x+y의 뜻은, 도메인 정확도가 x, 품목 정확도가 y라는 뜻이다)

### 위의 신경망의 비선형 활성화 함수를 쌍곡 탄젠트 함수로 적용
![그림 7 위의 신경망의 비선형 활성화 함수를 쌍곡 탄젠트 함수로 적용한 결과](https://github.com/minchoCoin/minchoCoin.github.io/assets/62372650/3dc5cd63-8746-4207-8ef7-8e2601a3c722)

(그림 7 위의 신경망의 비선형 활성화 함수를 쌍곡 탄젠트 함수로 적용한 결과)

훈련 데이터의 정확도는 0.734+0.380, 검증 데이터의 정확도는 0.740+0.340이다. 테스트 데이터의 정확도는 0.782+0.362이다. 정답이 (amazon, webcam, dslr)에 대한 데이터에 대해 (amazon,amazon,dslr)로 예측하였고, 정답이 (scissors, bike, projector)인 데이터에 대해 (speaker, desktop_computer, projector)로 예측하였다.
(정확도에서 x+y의 뜻은, 도메인 정확도가 x, 품목 정확도가 y라는 뜻이다)

# 결과에 대한 논의
## 꽃 이미지 분류 신경망

|     모델 구분                                        |     계층                                      |     훈련      데이터     정확도    |     검증      데이터     정확도    |     테스트      데이터     정확도    |
|------------------------------------------------------|-----------------------------------------------|------------------------------------|------------------------------------|--------------------------------------|
|     완전 연결     계층     (아담 알고리즘 적용)      |     [30,10]                                   |                           0.358    |                           0.240    |                             0.311    |
|     완전 연결     계층     (아담 알고리즘 미적용)    |     [30,10]                                   |                           0.454    |                           0.350    |                             0.388    |
|     (합성곱, 폴링,   합성곱, 폴링)                   |     (5x5:12,4x4, 3x3:12,2x2)                  |                           0.778    |                           0.490    |                             0.548    |
|     (합성곱, 폴링,   합성곱, 폴링, 합성곱, 폴링)     |     (3x3:6,2x2,3x3:12,     2x2,3x3:24,3x3)    |                           0.783    |                           0.640    |                             0.613    |

(표 1 꽃 이미지 분류 신경망 결과)

이번 실험에서는 아담 알고리즘을 적용했을때가 아담 알고리즘을 적용하지 않았을 때보다 더 낮은 정확도를 보여주었고, 모든 데이터에 대해 sunflower로 예측하였다. 합성곱과 폴링 계층으로 구성하여 학습하였을 때, 완전 연결 계층으로 학습했을 때보다 테스트 정확도가 16%p 정도 증가하였으며, 합성곱 및 폴링 계층을 각각 1개씩 더 늘렸을 때 테스트 정확도가 6.5%p 더 증가하였다. 합성곱 계층으로 10 epoch를 학습시켰을 때 지속적으로 손실값이 줄어들고 정확도도 지속적으로 상승하므로, 10epoch보다 더 많은 학습을 시키면 더 높은 정확도를 얻을 수 있을 것으로 보인다. 따라서, 이미지 학습에는 합성곱 신경망을 사용하는 것이 더 좋다는 것을 알 수 있다.

## 오피스31 다차원 분류 신경망

|     비선형      활성화      함수    |     훈련      도메인      정확도    |     훈련     품목     정확도    |     검증     도메인     정확도    |     검증     품목     정확도    |     테스트     도메인     정확도    |     테스트     품목     정확도    |
|-------------------------------------|-------------------------------------|---------------------------------|-----------------------------------|---------------------------------|-------------------------------------|-----------------------------------|
|     ReLU                            |     0.966                           |     0.937                       |     0.850                         |     0.550                       |     0.901                           |     0.536                         |
|     Sigmoid                         |     0.686                           |     0.039                       |     0.650                         |     0.040                       |     0.693                           |     0.043                         |
|     쌍곡      탄젠트                |     0.734                           |     0.380                       |     0.740                         |     0.340                       |     0.782                           |     0.362                         |

(표2 오피스31 다차원 분류 신경망 결과)

앞서 복합출력 실험에서 은닉 계층 (384,192,64,32,10)을 적용했을 때의 테스트 도메인 정확도와 테스트 품목 정확도가 각각 0.890, 0.283임을 생각하면 합성곱 신경망을 적용했을 때(ReLU 함수 적용) 테스트 도메인 정확도가 0.901, 테스트 품목 정확도가 0.536이 나온 것은 유의미한 상승임을 알 수 있다. 파라미터의 수가 더 적은 것을 감안하면 특히 더 그렇다.

같은 합성곱 신경망에 시그모이드 함수를 적용하였을 때는 분류를 제대로 못하는 모습을 보여준다. 모든 데이터에 대해 도메인은 amazon, 상품은 monitor로 예측하고 있다. 따라서 오피스31 분류 신경망에는 시그모이드 함수를 적용하는 것은 바람직하지 않은 것 같다.

쌍곡 탄젠트 함수를 적용하였을 때는 시그모이드 함수를 적용하였을 때보다는 정확도가 높지만, ReLU함수를 적용하였을 때보다는 정확도가 낮다.

따라서 합성곱 신경망에는 시그모이드 함수나 쌍곡 탄젠트 함수보다 ReLU함수를 비선형 활성화 함수로 사용하는 것이 바람직해보인다.

# 결론
꽃 이미지 분류 신경망과 오피스 31 다차원 분류 신경망을 합성곱 신경망을 적용하여 학습하고 결과를 확인하였다. 학습한 결과, 다층 퍼셉트론으로 완전 연결 계층을 이용해 학습한 것보다 합성곱 신경망을 적용(합성곱 계층과 폴링 계층 적용)하여 학습하였을 때 더 높은 성능을 보여주었다. 또한 오피스31 다차원 분류 신경망에서 비선형 활성화 함수로 ReLU를 적용했을 때까 가장 높은 성능을 보여주었다.

따라서 이미지 분류에는 합성곱 신경망을 사용하는 것이 완전 연결 계층을 사용하는 것보다 더 좋으며, 합성곱 신경망에는 시그모이드 함수나 쌍곡 탄젠트 함수보다 ReLU함수를 비선형 활성화 함수로 사용하는 것이 바람직해보인다.

# 참고 문헌
윤덕호 저, [파이썬 날코딩으로 알고 짜는 딥러닝], 한빛미디어, 2019